<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Lessons Learned</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>

<!-- HEADER + NAV -->
<header>
    <h1>LIS 500 Project 3</h1>
    <div class="topnav index-text">
        <a href="index.html">Home</a>
        <a href="ml-project.html">Project Scope</a>
        <a href="process.html">Process</a>
        <a class="active" href="lessons.html">Lessons Learned</a>
        <a href="video-test.html">Video and Test Model</a>
        <a href="project-statements.html">Project Statements</a>
    </div>
</header>

<section class="page-section">

    <h2>Lessons Learned</h2>

    <p>
        Working with our Teachable Machine model made it clear how easy it is for bias to appear, even when the project is small and simple. We trained the model to identify different skin tones using the webcam. Even with the samples we collected, the model consistently labeled most inputs as dark and rarely identified medium or light tones. This showed us how uneven or limited training data changes the way a model sees the world.
    </p>

    <p>
        This connected directly to Joy Buolamwini's work and the readings from this semester. She describes how algorithms often fail to recognize certain faces because of the data used to train them. Seeing our own project repeat this pattern helped us better understand how bias is built into machine learning systems. Even when the intention is good, the output still reflects the limits of the dataset.
    </p>

    <p>
        Our experience reinforced how important it is to think critically about data collection and representation. Small choices in the process shape the model's predictions and affect the accuracy and fairness of the system. This assignment helped us see that bias is not only something that happens in large tech companies. It can appear in projects like ours, where the stakes are low and the design is simple.
    </p>

    <h3>Example Output From Our Model</h3>

    <div class="lesson-image-wrapper">
        <img src="model.ex.png" alt="Example output from our model" class="lesson-image">
        <p class="landing-caption">The model frequently predicted dark tone even when the input was clearly different.</p>
    </div>

</section>

<footer class="index-text">
    <p>Â© 2025 by Aymen Hamdan, Alyssa Hannam, Casey Foubert</p>
</footer>

</body>
</html>

