<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Video & Test Model</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>

<!-- HEADER + NAV -->
<header>
    <h1>LIS 500 Project 3</h1>
    <div class="topnav index-text">
        <a href="index.html">Home</a>
        <a href="ml-project.html">Project Scope</a>
        <a href="process.html">Process</a>
        <a href="lessons.html">Lessons Learned</a>
        <a class="active" href="video-test.html">Video & Test Model</a>
        <a href="project-statements.html">Project Statements</a>
    </div>
</header>

<section class="page-section">

    <h2>Video Demonstrations of Our Models</h2>

    <!-- Teachable Machine Section -->
    <div class="video-section">
        <h3>Teachable Machine: Skin Tone Classification</h3>
        <p>
            In this video, we demonstrate our Teachable Machine model designed to classify skin tones using the user's webcam. 
            The model receives live video input and attempts to label the observed skin tone in real time. 
            During the demonstration, you can see that the model often classifies inputs as dark, even when medium or light tones are presented. 
            This behavior shows the limitations of our training data and illustrates how bias can be built into machine learning algorithms. 
            The video captures the step-by-step process of running the model and observing its predictions.
        </p>
        <div class="video-wrapper">
            <iframe src="https://www.youtube.com/embed/Ss9TCrf8v28" 
                    title="Teachable Machine Video" 
                    frameborder="0" 
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                    allowfullscreen>
            </iframe>
        </div>
    </div>

    <hr>

    <!-- p5.js Section -->
    <div class="video-section">
        <h3>p5.js Project Video</h3>
        <p>
            This video showcases our p5.js project, which visualizes data and responds to user input through interactive coding. 
            You can see how the program interprets user actions and changes the display accordingly. 
            The video highlights the logic behind the project, showing how inputs trigger visual effects and how the code handles different scenarios. 
            This demonstration helps illustrate the interactivity and creative problem-solving that went into building our p5.js model.
        </p>
        <div class="video-wrapper">
            <iframe src="https://www.youtube.com/embed/d6yPi4bd6pA" 
                    title="p5.js Project Video" 
                    frameborder="0" 
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                    allowfullscreen>
            </iframe>
        </div>
    </div>

</section>

<footer class="index-text">
    <p>Â© 2025 by Aymen Hamdan, Alyssa Hannam, Casey Foubert</p>
</footer>

</body>
</html>
